from platform import processor
import streamlit as st
from load_data import candidate_labels
import numpy as np
from load_data import *
import pickle
import torch
from BART_utils import get_taggs
from stqdm import stqdm
import pandas as pd

def transform_data(data, filetype = True):
    if filetype:
        df = pd.read_csv(uploaded_file)
    else:
        df = pd.read_excel(uploaded_file)
    return df
    
def convert_df(df):
   return df.to_csv().encode('utf-8')

stqdm.pandas()

st.title("Domain and Usage tagger")
st.subheader("ë¬¸ì¥ì„ ì…ë ¥í•˜ë©´ ì£¼ì œ / ìš©ë„ íƒœê·¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤ (ENì§€ì›)")
device = "cuda:0" if torch.cuda.is_available() else "cpu"
if device == "cpu":
    processor = "ğŸ–¥ï¸"
else:
    processor = "ğŸ’½"

st.subheader("Running on {}".format(device + processor))

bulk = st.checkbox("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì‹œê² ì–´ìš”?")
if not bulk:
    user_input = st.text_area(
    "ğŸ‘‡íƒœê·¸ë¥¼ ìƒì„±í•  ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš” - í˜„ì¬ ì˜ë¬¸ë§Œ ì§€ì›ë©ë‹ˆë‹¤.", """NLI-based Zero Shot Text Classification
Yin et al. proposed a method for using pre-trained NLI models as a ready-made zero-shot sequence classifiers. The method works by posing the sequence to be classified as the NLI premise and to construct a hypothesis from each candidate label. The probabilities for entailment and contradiction are then converted to label probabilities."""
)

    thred = st.slider(
        "ğŸ‘‡íƒœê·¸ ìƒì„± thredhold ì„¤ì •. ê²°ê³¼ê°€ ë‚˜ì˜¤ì§€ ì•Šì„ê²½ìš°, thresholdë¥¼ 0ì— ê°€ê¹ê²Œ ë‚®ì¶”ì„¸ìš”!",
        0.0,
        1.0,
        0.5,
        step=0.01,
    )
    if thred:
        st.write(thred, " ì´ìƒì˜ confidence levelì¸ íƒœê·¸ë§Œ ìƒì„±í•©ë‹ˆë‹¤.")

    maximum = st.number_input("ğŸ‘‡ìµœëŒ€ íƒœê·¸ ê°¯ìˆ˜ ì„¤ì •", 0, 10, 5, step=1)
    st.write("ìµœëŒ€ {} ê°œì˜ íƒœê·¸ ìƒì„±".format(maximum))

    check_source = st.checkbox("ğŸ·ï¸ìš©ì²˜ / ì¶œì²˜ íƒœê·¸ ìƒì„±")
    submit = st.button("ğŸ‘ˆí´ë¦­í•´ì„œ íƒœê·¸ ìƒì„±")
    if submit:

        with st.spinner("âŒ›íƒœê·¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            result = get_taggs(user_input, candidate_labels, thred)
            result = result[:maximum]
        st.subheader("ğŸ”í˜¹ì‹œ ì´ëŸ° ì£¼ì œì˜ ë¬¸ì¥ì¸ê°€ìš”? : ")
        if len(result) == 0:
            st.write("ğŸ˜¢ì €ëŸ°..ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. Thresholdë¥¼ ë‚®ì¶°ë³´ì„¸ìš”!")
        for i in result:
            st.write("â¡ï¸ " + i[0], "{}%".format(int(i[1] * 100)))

        if check_source:
            with st.spinner("âŒ›ì‚¬ìš© ëª©ì  íƒœê·¸ ìƒì„±ì¤‘..."):
                source_result = get_taggs(user_input, source, thred=0)
            st.subheader("ğŸ”í˜¹ì‹œ ì´ ì‚¬ìš©ëª©ì ì˜ ë¬¸ì¥ì¸ê°€ìš”? : ")
            for i in source_result[:3]:
                st.write("ğŸ·ï¸ " + i[0], "{}%".format(int(i[1] * 100)))


else:
    st.write("ğŸ”ì»¬ëŸ¼ëª…ì„ 'text'ë¡œ ì„¤ì •í•´, íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
    filetype = st.checkbox("ğŸ‘ˆUsing CSV? (ì²´í¬í•˜ì§€ ì•Šìœ¼ë©´ xlsx ì‚¬ìš©): ")
    uploaded_file = st.file_uploader("Choose an csv file")
    if uploaded_file is not None:
        df = transform_data(uploaded_file, filetype)
        st.write(df)
        thred = st.slider(
            "ğŸ‘‡íƒœê·¸ ìƒì„± thredhold ì„¤ì •. ê²°ê³¼ê°€ ë‚˜ì˜¤ì§€ ì•Šì„ê²½ìš°, thresholdë¥¼ 0ì— ê°€ê¹ê²Œ ë‚®ì¶”ì„¸ìš”!",
            0.0,
            1.0,
            0.5,
            step=0.01,
        )
        if thred:
            st.write(thred, " ì´ìƒì˜ confidence levelì¸ íƒœê·¸ë§Œ ìƒì„±í•©ë‹ˆë‹¤.")

        maximum = st.number_input("ğŸ‘‡ìµœëŒ€ íƒœê·¸ ê°¯ìˆ˜ ì„¤ì •", 0, 10, 5, step=1)
        st.write("ìµœëŒ€ {} ê°œì˜ íƒœê·¸ ìƒì„±".format(maximum))

        check_source = st.checkbox("ğŸ·ï¸ìš©ì²˜ / ì¶œì²˜ íƒœê·¸ ìƒì„±")
        submit = st.button("ğŸ‘ˆí´ë¦­í•´ì„œ íƒœê·¸ ìƒì„±")

        if submit:
            with st.spinner("âŒ›íƒœê·¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                df["generated_tag"] = df["text"].progress_apply(lambda x : get_taggs(x, candidate_labels, thred)[:maximum])
                
            if check_source:
                with st.spinner("âŒ›ì‚¬ìš© ëª©ì  íƒœê·¸ ìƒì„±ì¤‘..."):
                    df["source"] = df["text"].progress_apply(lambda x : get_taggs(x, source, thred=0))

            csv = convert_df(df)
            
            to_json = {}
            for idx, row in df.iterrows():
                to_json[row.text] = {}
                to_json[row.text]["generated_tag"] = row.generated_tag
                to_json[row.text]["source"] = row.source
            
            st.download_button(
               "Press to Download",
               csv,
               "file.csv",
               "text/csv",
               key='download-csv'
            )
            st.write("ğŸ””Outcome: ")
            st.write(to_json)